{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f066f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --pre azure-ai-projects\n",
    "#%pip install pypandoc\n",
    "#%pip install azure-identity\n",
    "#%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfe2038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "from azure.ai.agents.models import MessageTextContent, ListSortOrder\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecfe94c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_url= \"https://gitmcp.io/Arturo-Quiroga-MSFT/RED-TEAMING\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5dcd130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent, agent ID: asst_YLTHxRCT4qjbBsJ7LMor9rb1\n",
      "Created thread, thread ID: thread_TMRqhWNmh5mQq0NkaT7Eag26\n",
      "Created message, message ID: msg_YIAwBeklZRTboVx1IwV9ABzv\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.COMPLETED\n",
      "Run step: step_jmcnMKMiGGRZZbKliSRhBqti, status: RunStepStatus.COMPLETED, type: RunStepType.MESSAGE_CREATION\n",
      "Run step: step_1kFurXahHnxaWQY5a8mYLrt5, status: RunStepStatus.COMPLETED, type: RunStepType.TOOL_CALLS\n",
      "Tool call details:\n",
      "{\n",
      "  \"id\": \"call_gCtMZiJXBd64SOy5hy2VLOmq\",\n",
      "  \"type\": \"mcp\",\n",
      "  \"arguments\": \"{}\",\n",
      "  \"name\": \"fetch_RED_TEAMING_documentation\",\n",
      "  \"output\": \"# AI Red Teaming Agent (Preview)\\n\\n> **\\u26a0\\ufe0f DISCLAIMER**\\n>\\n> The author of this repository **did not create, author, or curate any of the red teaming prompts** used to test or evaluate the filtering capabilities of AI models or agents. All adversarial prompts, attack objectives, and risk category examples are sourced from Microsoft's open-source [PyRIT](https://github.com/microsoft/pyrit) (Python Risk Identification Tool) and/or the Azure AI Evaluation SDK. These prompts are provided solely for research, evaluation, and safety testing purposes. Use them responsibly and in accordance with all applicable laws and ethical guidelines.\\n\\n---\\n\\n## Overview\\n\\nThe **AI Red Teaming Agent** is a tool designed to help organizations proactively identify safety risks in generative AI systems during design and development. By integrating Microsoft's open-source PyRIT red teaming capabilities directly into Azure AI Foundry, teams can automatically scan their model and application endpoints for risks, simulate adversarial probing, and generate detailed reports.\\n\\n---\\n\\n## Features\\n\\n- **Automated Adversarial Probing:** Simulate attacks on your AI system using curated seed prompts and advanced attack strategies.\\n- **Integration with Azure AI Foundry:** Seamlessly connect to your Azure AI projects and model deployments.\\n- **Flexible Targeting:** Scan base models, application callbacks, or PyRIT prompt targets.\\n- **Customizable Risk Categories:** Focus on specific risk areas such as Violence, Hate/Unfairness, Sexual, and Self-Harm.\\n- **Detailed Reporting:** Generate comprehensive reports on identified risks.\\n\\n---\\n\\n## How AI Red Teaming Works\\n\\nThe agent automates adversarial probing of your target AI system. It uses a curated dataset of seed prompts or attack objectives per supported risk category. Attack strategies from PyRIT can help bypass or subvert the AI system\\u2019s safety alignments.\\n\\nFor example, a direct question about illegal activity may be refused by the model, but an attack strategy (like character flipping) may trick the model into responding.\\n\\n---\\n\\n## Supported Azure Regions\\n\\nCurrently, the AI Red Teaming Agent is only available in the following Azure regions:\\n\\n- East US2\\n- Sweden Central\\n- France Central\\n- Switzerland West\\n\\nEnsure your Azure AI Project is located in one of these regions.\\n\\n---\\n\\n## Installation\\n\\nInstall the required packages:\\n\\n```bash\\npip install azure-identity azure-ai-agents\\npip install azure-ai-evaluation\\npip install \\\"azure-ai-evaluation[redteam]\\\"\\n```\\n\\n---\\n\\n## Usage\\n\\n### 1. Set Up Environment Variables\\n\\nSet the following environment variables (e.g., in a `.env` file):\\n\\n- `PROJECT_ENDPOINT`: Your Azure AI Foundry project endpoint\\n- `MODEL_ENDPOINT`: Your Azure OpenAI model endpoint\\n- `MODEL_API_KEY`: API key for your model (if not using Entra ID)\\n- `MODEL_DEPLOYMENT_NAME`: Name of your model deployment\\n\\n### 2. Instantiate the Red Teaming Agent\\n\\n```python\\nfrom azure.identity import DefaultAzureCredential\\nfrom azure.ai.evaluation.red_team import RedTeam\\n\\nazure_ai_project = os.getenv(\\\"PROJECT_ENDPOINT\\\")\\nred_team_agent = RedTeam(\\n    azure_ai_project=azure_ai_project,\\n    credential=DefaultAzureCredential()\\n)\\n```\\n\\n### 3. Supported Targets\\n\\nYou can scan various targets:\\n\\n#### a. Model Configuration\\n\\n```python\\nazure_openai_config = {\\n    \\\"azure_endpoint\\\": os.getenv(\\\"MODEL_ENDPOINT\\\"),\\n    \\\"api_key\\\": os.getenv(\\\"MODEL_API_KEY\\\"),\\n    \\\"azure_deployment\\\": os.getenv(\\\"MODEL_DEPLOYMENT_NAME\\\"),\\n}\\nred_team_result = await red_team_agent.scan(target=azure_openai_config)\\n```\\n\\n#### b. Simple Callback\\n\\n```python\\ndef simple_callback(query: str) -> str:\\n    return \\\"I'm an AI assistant that follows ethical guidelines. I cannot provide harmful content.\\\"\\n\\nred_team_result = await red_team_agent.scan(target=simple_callback)\\n```\\n\\n#### c. Complex Callback\\n\\n```python\\nasync def advanced_callback(messages, stream=False, session_state=None, context=None):\\n    response = \\\"I'm an AI assistant that follows safety guidelines. I cannot provide harmful content.\\\"\\n    formatted_response = {\\n        \\\"content\\\": response,\\n        \\\"role\\\": \\\"assistant\\\"\\n    }\\n    return {\\\"messages\\\": [formatted_response]}\\n\\nred_team_result = await red_team_agent.scan(target=advanced_callback)\\n```\\n\\n#### d. PyRIT Prompt Target\\n\\n```python\\nfrom pyrit.prompt_target import OpenAIChatTarget\\n\\nchat_target = OpenAIChatTarget(\\n    model_name=os.environ.get(\\\"MODEL_DEPLOYMENT_NAME\\\"),\\n    endpoint=os.environ.get(\\\"MODEL_ENDPOINT\\\"),\\n    api_key=os.environ.get(\\\"MODEL_API_KEY\\\")\\n)\\nred_team_result = await red_team_agent.scan(target=chat_target)\\n```\\n\\n---\\n\\n## Customization\\n\\nYou can specify risk categories and the number of attack objectives:\\n\\n```python\\nfrom azure.ai.evaluation.red_team import RiskCategory\\n\\nred_team_agent = RedTeam(\\n    azure_ai_project=azure_ai_project,\\n    credential=DefaultAzureCredential(),\\n    risk_categories=[\\n        RiskCategory.Violence,\\n        RiskCategory.HateUnfairness,\\n        RiskCategory.Sexual,\\n        RiskCategory.SelfHarm\\n    ],\\n    num_objectives=5\\n)\\n```\\n\\n---\\n\\n## References\\n\\n- [Microsoft Learn: Run scans with AI Red Teaming Agent](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/run-scans-ai-red-teaming-agent)\\n- [PyRIT GitHub Repository](https://github.com/microsoft/pyrit)\\n\\n---\\n\\n## License\\n\\nThis project is licensed under the MIT\"\n",
      "}\n",
      "MessageRole.USER: what is the purpose of this repository?\n",
      "MessageRole.AGENT: The purpose of the Arturo-Quiroga-MSFT/RED-TEAMING repository is to provide an AI Red Teaming Agentâ€”a tool designed to help organizations proactively identify safety risks in generative AI systems during their design and development phases.\n",
      "\n",
      "Key goals and features include:\n",
      "\n",
      "- Automating adversarial probing of AI systems using attack strategies and prompts sourced from Microsoft's open-source PyRIT (Python Risk Identification Tool) and the Azure AI Evaluation SDK.\n",
      "- Simulating attacks to test the robustness and safety filtering capabilities of language models or AI agents.\n",
      "- Integrating directly with Azure AI Foundry for seamless evaluation of deployed models and applications.\n",
      "- Focusing on important risk categories such as Violence, Hate/Unfairness, Sexual content, and Self-Harm.\n",
      "- Generating detailed reports on identified risks to help improve AI safety defenses.\n",
      "\n",
      "In essence, this repository helps organizations test and manage the risks associated with deploying large language models or similar generative AI technologies, making the process more automated, thorough, and integrated with Azure tools.\n",
      "\n",
      "References:\n",
      "- Overview and features summarized from the repository documentation.\n",
      "- More info: [Microsoft Learn Documentation](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/run-scans-ai-red-teaming-agent)\n"
     ]
    }
   ],
   "source": [
    "project_client = AIProjectClient(\n",
    "    endpoint=os.getenv(\"PROJECT_ENDPOINT3\"),\n",
    "    credential=DefaultAzureCredential()\n",
    ")\n",
    "\n",
    "# Create an agent that uses the MCP server\n",
    "# The agent will use the MCP server to answer questions\n",
    "# The MCP server is a custom tool that allows the agent to access external data\n",
    "# In this case, we are using a GitHub repository as the MCP server\n",
    "with project_client:\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=os.getenv(\"MODEL_DEPLOYMENT_NAME\"), \n",
    "        name=\"my-mcp-agent\", \n",
    "        instructions=\"You are a helpful assistant. Use the tools provided to answer the user's questions. Be sure to cite your sources.\",\n",
    "        tools= [\n",
    "            {\n",
    "                \"type\": \"mcp\",\n",
    "\t\t\"server_label\": \"REDTEAMING\",\n",
    "                \"server_url\": server_url,\n",
    "                \"require_approval\": \"never\"\n",
    "            }\n",
    "        ],\n",
    "        tool_resources=None\n",
    "    )\n",
    "    print(f\"Created agent, agent ID: {agent.id}\")\n",
    "\n",
    "    # Create a thread and a message to start the run\n",
    "    # This is where the user will ask a question to the agent\n",
    "    # and the agent will use the MCP server to answer it.\n",
    "    thread = project_client.agents.threads.create()\n",
    "    print(f\"Created thread, thread ID: {thread.id}\")\n",
    "\n",
    "    message = project_client.agents.messages.create(\n",
    "        thread_id=thread.id, role=\"user\", content=\"what is the purpose of this repository?\",\n",
    "    )\n",
    "    print(f\"Created message, message ID: {message.id}\")\n",
    "\n",
    "    run = project_client.agents.runs.create(thread_id=thread.id, agent_id=agent.id)\n",
    "\n",
    "\n",
    "    # Poll the run as long as run status is queued or in progress\n",
    "    while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "        # Wait for a second\n",
    "        time.sleep(1)\n",
    "        run = project_client.agents.runs.get(thread_id=thread.id, run_id=run.id)\n",
    "        print(f\"Run status: {run.status}\")\n",
    "\n",
    "    if run.status == \"failed\":\n",
    "        print(f\"Run error: {run.last_error}\")\n",
    "\n",
    "    run_steps = project_client.agents.run_steps.list(thread_id=thread.id, run_id=run.id)\n",
    "    for step in run_steps:\n",
    "        print(f\"Run step: {step.id}, status: {step.status}, type: {step.type}\")\n",
    "        if step.type == \"tool_calls\":\n",
    "            print(f\"Tool call details:\")\n",
    "            for tool_call in step.step_details.tool_calls:\n",
    "                print(json.dumps(tool_call.as_dict(), indent=2))\n",
    "\n",
    "    messages = project_client.agents.messages.list(thread_id=thread.id, order=ListSortOrder.ASCENDING)\n",
    "    for data_point in messages:\n",
    "        last_message_content = data_point.content[-1]\n",
    "        if isinstance(last_message_content, MessageTextContent):\n",
    "            print(f\"{data_point.role}: {last_message_content.text.value}\")\n",
    "\n",
    "    #project_client.agents.delete_agent(agent.id)\n",
    "    #print(f\"Deleted agent, agent ID: {agent.id}\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
