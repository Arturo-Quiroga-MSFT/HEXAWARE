{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6a6a9ba-90a1-4808-b8b7-584cf8371b0b",
   "metadata": {},
   "source": [
    "# Deep Research tool with Azure AI Foundry (preview)\n",
    "\n",
    "<img src=\"https://learn.microsoft.com/en-us/azure/ai-services/agents/media/agent-service-the-glue.png\" width=800>\n",
    "\n",
    "The **Deep Research tool** in the Azure AI Foundry Agent Service enables you to integrate a web-based research capability into your systems. The Deep Research capability is a specialized AI capability designed to perform in-depth, multi-step research using data from the public web.\n",
    "\n",
    "> https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/deep-research\n",
    "\n",
    "The **o3-deep-research model** and the GPT model deployments should be part of your AI Foundry project resulting in all three resources in the same Azure subscription and same region. Supported regions are **West US and Norway East.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd47f876-0262-4406-8c7b-8bcb671720cd",
   "metadata": {},
   "source": [
    "At its core, **Deep Research** leverages a combination of OpenAI and Microsoft technologies, including **o3-deep-research**, various GPT models, and **Bing Search Grounding**, when integrated into an agent.\n",
    "\n",
    "- When an agent with Deep Research integration receives a research request — whether from a user or another application — it utilizes GPT-4o and GPT-4.1 to interpret the intent, fill in any missing details, and define a clear, actionable scope for the task.\n",
    "- Once the task is defined, the agent activates the Bing-powered grounding tool to gather a refined selection of recent, high-quality web content.\n",
    "- Following this, the o3-deep-research agent begins the research process by reasoning through the collected information. Rather than merely summarizing content, it evaluates, adapts, and synthesizes insights from multiple sources, adjusting its approach as new data emerges.\n",
    "- The entire process culminates in a structured report that not only provides the answer but also includes the model’s reasoning path, source citations, and any clarifications requested during the session, as explained by Arenas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdfeb20-fc2a-4c45-8c84-72b346f34fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --pre azure-ai-projects\n",
    "#%pip install pypandoc\n",
    "#%pip install azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb3437-0bc5-481c-bf34-109d466c99eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import pypandoc\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from azure.ai.agents import AgentsClient\n",
    "from azure.ai.agents.models import DeepResearchTool, MessageRole, ThreadMessage\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from IPython.display import display, FileLink, Markdown\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fcc33e-1a1a-44e7-8e60-81c03ac44366",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1265de15-5634-4f8c-9a5d-a56bd8277ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Today is {datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8579f189-6729-44c0-9377-5eeeb9e6d71a",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ac764c-9074-493b-8050-7f3bf2eb4cb1",
   "metadata": {},
   "source": [
    "> Only available now in \"West US\" and \"Norway East\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bdbc2a-b494-4777-956d-bc531e585b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Foundry project\n",
    "project_endpoint = \"https://aq-ai-foundry-sweden-central.services.ai.azure.com/api/projects/firstProject\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9f6e44-09d1-4b82-adb1-bb4f405969bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4.1\"  # a generic gpt model\n",
    "deep_research_model = \"o3-deep-research\"  # the new o3 deep research model deployed in your AI Foundry\n",
    "\n",
    "bingservice = \"aqbinggrounding002\"  # The Bing connection service in your AI foundry project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4de748d-439e-4aea-9378-5fd1ab34edc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = \"documents\"\n",
    "\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd18e4a4-5ca2-4830-b101-b1c8e962cd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.today().strftime('%d%b%Y_%H%M%S')\n",
    "\n",
    "md_results_file = os.path.join(RESULTS_DIR, f\"deep_research_results_{now}.md\")  # The name of the markdown output file\n",
    "docx_file = os.path.join(RESULTS_DIR, f\"deep_research_results_{now}.docx\")  # .docx outpyt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29e2ddc-128b-46c6-ab8d-7106c0d0633f",
   "metadata": {},
   "source": [
    "## Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8931e94f-24c6-4704-940f-c36b88faa7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_print_new_agent_response(\n",
    "    thread_id: str,\n",
    "    agents_client: AgentsClient,\n",
    "    last_message_id: Optional[str] = None,\n",
    ") -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Fetches and prints the latest response from an agent in a given thread.\n",
    "\n",
    "    Args:\n",
    "        thread_id (str): The ID of the thread to fetch the agent's response from.\n",
    "        agents_client (AgentsClient): The client used to interact with the agents service.\n",
    "        last_message_id (Optional[str], optional): The ID of the last message that was processed. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The ID of the latest message if there is new content, otherwise returns the last_message_id.\n",
    "    \"\"\"\n",
    "    response = agents_client.messages.get_last_message_by_role(\n",
    "        thread_id=thread_id,\n",
    "        role=MessageRole.AGENT,\n",
    "    )\n",
    "    if not response or response.id == last_message_id:\n",
    "        return last_message_id  # No new content\n",
    "\n",
    "    print(\"\\nAgent response:\")\n",
    "    print(\"\\n\".join(t.text.value for t in response.text_messages))\n",
    "\n",
    "    for ann in response.url_citation_annotations:\n",
    "        print(\n",
    "            f\"URL Citation: [{ann.url_citation.title}]({ann.url_citation.url})\"\n",
    "        )\n",
    "\n",
    "    return response.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa53624-d373-4755-a2e0-bb0767cbf734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_research_summary(message: ThreadMessage,\n",
    "                            filepath: str = md_results_file) -> None:\n",
    "    \"\"\"\n",
    "    Creates a research summary from the provided message and writes it to a file.\n",
    "\n",
    "    Args:\n",
    "        message (ThreadMessage): The message containing the content for the research summary.\n",
    "        filepath (str, optional): The path to the file where the research summary will be written in a markdown format.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not message:\n",
    "        print(\"Error: No message content provided\")\n",
    "        return\n",
    "\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as fp:\n",
    "        # Write text summary\n",
    "        text_summary = \"\\n\\n\".join(\n",
    "            [t.text.value.strip() for t in message.text_messages])\n",
    "        fp.write(text_summary)\n",
    "\n",
    "        # Write unique URL citations, if present\n",
    "        if message.url_citation_annotations:\n",
    "            fp.write(\"\\n\\n## References\\n\")\n",
    "            seen_urls = set()\n",
    "            for ann in message.url_citation_annotations:\n",
    "                url = ann.url_citation.url\n",
    "                title = ann.url_citation.title or url\n",
    "                if url not in seen_urls:\n",
    "                    fp.write(f\"- [{title}]({url})\\n\")\n",
    "                    seen_urls.add(url)\n",
    "\n",
    "    print(f\"Research summary written to '{filepath}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfe977e-98c3-4e6c-818b-909ae62f105a",
   "metadata": {},
   "source": [
    "## Project & tool definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c5bec5-e5c7-4922-ae0b-794a00525b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_client = AIProjectClient(\n",
    "    endpoint=project_endpoint,\n",
    "    credential=DefaultAzureCredential(),\n",
    ")\n",
    "\n",
    "conn_id = project_client.connections.get(name=bingservice).id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe15af61-7b30-4f7e-8cb6-3d85d981e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_research_tool = DeepResearchTool(\n",
    "    bing_grounding_connection_id=conn_id,\n",
    "    deep_research_model=deep_research_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00d700b-703f-42e5-823a-e7f9e45c9b5b",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6de670-5843-4025-b0cf-ababd4508549",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Give me the latest research into magentic-ui from Microsoft's autogen over the last year. Do not ask questions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d955d8f1-920c-481d-bfd4-c8315ba74c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "with project_client:\n",
    "    with project_client.agents as agents_client:\n",
    "        agent = agents_client.create_agent(\n",
    "            model=model,\n",
    "            name=\"deep-research-agent\",\n",
    "            instructions=\n",
    "            \"You are a helpful agent that assists in researching scientific topics.\",\n",
    "            tools=deep_research_tool.definitions,\n",
    "        )\n",
    "\n",
    "        print(f\"🎉 Created agent, ID: {agent.id}\")\n",
    "\n",
    "        thread = agents_client.threads.create()\n",
    "        print(f\"🧵 Created thread, ID: {thread.id}\")\n",
    "\n",
    "        # Create message to thread\n",
    "        message = agents_client.messages.create(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=(prompt),\n",
    "        )\n",
    "        print(f\"📩 Created message, ID: {message.id}\")\n",
    "        print(\n",
    "            f\"⏳ Start processing the message... this may take a few minutes to finish. Be patient!\"\n",
    "        )\n",
    "\n",
    "        run = agents_client.runs.create(thread_id=thread.id, agent_id=agent.id)\n",
    "        last_message_id = None\n",
    "\n",
    "        while run.status in (\"queued\", \"in_progress\"):\n",
    "            time.sleep(1)\n",
    "            run = agents_client.runs.get(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "            last_message_id = fetch_and_print_new_agent_response(\n",
    "                thread_id=thread.id,\n",
    "                agents_client=agents_client,\n",
    "                last_message_id=last_message_id,\n",
    "            )\n",
    "            print(f\"🔄 Run status: {run.status}\")\n",
    "\n",
    "        print(f\"✅ Run finished with status: {run.status}, ID: {run.id}\")\n",
    "\n",
    "        if run.status == \"failed\":\n",
    "            print(f\"❌ Run failed: {run.last_error}\")\n",
    "\n",
    "        final_message = agents_client.messages.get_last_message_by_role(\n",
    "            thread_id=thread.id, role=MessageRole.AGENT)\n",
    "        if final_message:\n",
    "            create_research_summary(final_message)\n",
    "\n",
    "        # Clean-up and delete the agent once the run is finished.\n",
    "        #agents_client.delete_agent(agent.id)\n",
    "        #print(\"🗑️ Deleted agent\")\n",
    "\n",
    "elapsed = time.time() - start\n",
    "minutes, seconds = divmod(elapsed, 60)\n",
    "print(f\"\\nElapsed time = {minutes:.0f} minutes and {seconds:.0f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5257758c-7d0d-43fa-bebd-effbebad9dc7",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1383d583-075c-441b-a089-a07e85958af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh $md_results_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3629fe2-f850-43c8-a9fb-94666860c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(md_results_file, 'r', encoding='utf-8') as file:\n",
    "    markdown_content = file.read()\n",
    "    display(Markdown(markdown_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debed3a4-0986-4335-9cc5-0351b2cc0654",
   "metadata": {},
   "source": [
    "### Exporting results into a docx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f21b63-8749-459e-b7c1-e6640336206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pypandoc.convert_file(md_results_file, 'docx', outputfile=docx_file)\n",
    "print(f\"{md_results_file} has been converted to {docx_file}\\n\")\n",
    "\n",
    "!ls $docx_file -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d73423e-69d0-4bd5-a6bc-8758670ad536",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = FileLink(path=docx_file)\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860b9b8f-4c43-4994-bfbc-ad2b6e15702d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv7 (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
